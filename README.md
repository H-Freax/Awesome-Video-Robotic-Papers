# Awesome-Video-Robotic-Papers

This repository compiles a list of papers related to the application of video technology in the field of robotics.  Continual improvements are being made to this repository. If you come across any relevant papers that should be included, please don't hesitate to open an issue.

## Review


## Robot Arm

- Vid2Robot: End-to-end Video-conditioned Policy Learning with Cross-Attention Transformers
  - Vidhi Jain, Maria Attarian, Nikhil J Joshi, Ayzaan Wahid, Danny Driess, Quan Vuong, Pannag R Sanketi, Pierre Sermanet, Stefan Welker, Christine Chan, Igor Gilitschenski, Yonatan Bisk, Debidatta Dwibedi 
  - [Paper](https://arxiv.org/abs/2403.12943)
  - [Website](https://vid2robot.github.io/)

- OpenVLA: An Open-Source Vision-Language-Action Model
  - Moo Jin Kim, Karl Pertsch, Siddharth Karamcheti, Ted Xiao, Ashwin Balakrishna, Suraj Nair, Rafael Rafailov, Ethan Foster, Grace Lam, Pannag Sanketi, Quan Vuong, Thomas Kollar, Benjamin Burchfiel, Russ Tedrake, Dorsa Sadigh, Sergey Levine, Percy Liang, Chelsea Finn
  - [Paper](https://arxiv.org/abs/2406.09246)
  - [Website](https://openvla.github.io/)
  - [Code](https://github.com/openvla/openvla)

- Video Language Planning
  - Yilun Du, Mengjiao Yang, Pete Florence, Fei Xia, Ayzaan Wahid, Brian Ichter, Pierre Sermanet, Tianhe Yu, Pieter Abbeel, Joshua B. Tenenbaum, Leslie Kaelbling, Andy Zeng, Jonathan Tompson
  - [Paper](https://arxiv.org/abs/2310.10625)
  - [Website](https://video-language-planning.github.io/)
  - [Code](https://github.com/video-language-planning/vlp_code)
 
## SPOT
- Track2Act: Predicting Point Tracks from Internet Videos Enables Diverse Zero-shot Manipulation
  - Homanga Bharadhwaj, Roozbeh Mottaghi*, Abhinav Gupta*, Shubham Tulsiani*
  - [Paper](https://arxiv.org/abs/2405.01527)
  - [Website](https://homangab.github.io/track2act/)
  - [Code](https://github.com/homangab/Track-2-Act/)

## Other Useful Sources

[Awesome-VideoLLM-Papers](https://github.com/yyyujintang/Awesome-VideoLLM-Papers)

[Awesome-LLMs-for-Video-Understanding](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding)

[VLM-Eval: A General Evaluation on Video Large Language Models](https://github.com/zyayoung/Awesome-Video-LLMs)

[LLMs Meet Multimodal Generation and Editing: A Survey](https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation)
